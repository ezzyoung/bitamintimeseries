import os
import numpy as np
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, f1_score, precision_score, recall_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# âœ… ê²½ë¡œ ì„¤ì •
BASE_DIR = "c:/BitaminDirectory/Sleep_Anomaly_Detection"
split_dir = os.path.join(BASE_DIR, "Database", "processed", "split")
model_save_path = os.path.join(BASE_DIR, "trained_models", "rf_baseline_model.pkl")
os.makedirs(os.path.dirname(model_save_path), exist_ok=True)

# âœ… ë°ì´í„° ë¡œë“œ
def load_data(split_dir, train_ratio=0.6, val_ratio=0.6):
    def partial_load(filename, ratio):
        path = os.path.join(split_dir, filename)
        arr = np.load(path, mmap_mode="r")
        sample_count = max(1, int(arr.shape[0] * ratio))
        return arr[:sample_count]

    X_train = np.concatenate([
        partial_load("X_train_0.npy", train_ratio),
        partial_load("X_train_1.npy", train_ratio)
    ])
    y_train = np.concatenate([
        partial_load("y_train_0.npy", train_ratio),
        partial_load("y_train_1.npy", train_ratio)
    ])
    X_val = np.concatenate([
        partial_load("X_val_0.npy", val_ratio),
        partial_load("X_val_1.npy", val_ratio)
    ])
    y_val = np.concatenate([
        partial_load("y_val_0.npy", val_ratio),
        partial_load("y_val_1.npy", val_ratio)
    ])
    return X_train, y_train, X_val, y_val

# âœ… í•™ìŠµ ë° í‰ê°€
def run_rf_baseline(X_train, y_train, X_val, y_val):
    # âœ… Flatten: (N, C, T) â†’ (N, C*T)
    X_train = X_train.reshape(X_train.shape[0], -1)
    X_val = X_val.reshape(X_val.shape[0], -1)

    pipeline = make_pipeline(
        StandardScaler(),
        RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            class_weight='balanced',
            random_state=42
        )
    )

    pipeline.fit(X_train, y_train)

    # âœ… ì €ì¥
    joblib.dump(pipeline, model_save_path)
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")

    # âœ… í•™ìŠµ í‰ê°€
    y_train_pred = pipeline.predict(X_train)
    y_train_score = pipeline.predict_proba(X_train)[:, 1]

    print("\nâœ… [Train Set] í‰ê°€ ê²°ê³¼")
    print(classification_report(y_train, y_train_pred, digits=4))
    print(f"AUC       : {roc_auc_score(y_train, y_train_score):.4f}")
    print(f"F1-score  : {f1_score(y_train, y_train_pred):.4f}")
    print(f"Precision : {precision_score(y_train, y_train_pred):.4f}")
    print(f"Recall    : {recall_score(y_train, y_train_pred):.4f}")

    # âœ… ê²€ì¦ í‰ê°€
    y_val_pred = pipeline.predict(X_val)
    y_val_score = pipeline.predict_proba(X_val)[:, 1]

    print("\nğŸ“Š [Validation Set] í‰ê°€ ê²°ê³¼")
    print(classification_report(y_val, y_val_pred, digits=4))
    print(f"AUC       : {roc_auc_score(y_val, y_val_score):.4f}")
    print(f"F1-score  : {f1_score(y_val, y_val_pred):.4f}")
    print(f"Precision : {precision_score(y_val, y_val_pred):.4f}")
    print(f"Recall    : {recall_score(y_val, y_val_pred):.4f}")

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    X_train, y_train, X_val, y_val = load_data(split_dir, train_ratio=0.6, val_ratio=0.6)
    print(f"âœ… í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(X_train)}, ê²€ì¦ ìƒ˜í”Œ ìˆ˜: {len(X_val)}")
    print("ğŸš€ RandomForest Baseline í•™ìŠµ ì‹œì‘")
    run_rf_baseline(X_train, y_train, X_val, y_val)
