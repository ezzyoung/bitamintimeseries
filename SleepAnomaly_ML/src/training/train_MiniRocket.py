import os
import numpy as np
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, f1_score, precision_score, recall_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sktime.transformations.panel.rocket import MiniRocketMultivariate
from sklearn.base import BaseEstimator, TransformerMixin

# âœ… ì‚¬ìš©ì ì •ì˜ ë˜í¼: transformerë„ pipelineì— ë„£ê¸° ìœ„í•¨
class MiniRocketWrapper(BaseEstimator, TransformerMixin):
    def __init__(self, num_kernels=1000):
        self.num_kernels = num_kernels
        self.transformer = MiniRocketMultivariate(num_kernels=self.num_kernels)

    def fit(self, X, y=None):
        return self.transformer.fit(X, y)

    def transform(self, X):
        return self.transformer.transform(X)

# âœ… ê²½ë¡œ ì„¤ì •
BASE_DIR = "c:/BitaminDirectory/Sleep_Anomaly_Detection"
split_dir = os.path.join(BASE_DIR, "Database", "processed", "split")
model_save_path = os.path.join(BASE_DIR, "trained_models", "minirocket_rf_pipeline.pkl")
os.makedirs(os.path.dirname(model_save_path), exist_ok=True)

# âœ… ë°ì´í„° ë¡œë“œ
def load_data(split_dir, train_ratio=0.6, val_ratio=0.6):
    def partial_load(filename, ratio):
        path = os.path.join(split_dir, filename)
        arr = np.load(path, mmap_mode="r")
        sample_count = max(1, int(arr.shape[0] * ratio))
        return arr[:sample_count]

    X_train = np.concatenate([
        partial_load("X_train_0.npy", train_ratio),
        partial_load("X_train_1.npy", train_ratio)
    ])
    y_train = np.concatenate([
        partial_load("y_train_0.npy", train_ratio),
        partial_load("y_train_1.npy", train_ratio)
    ])
    X_val = np.concatenate([
        partial_load("X_val_0.npy", val_ratio),
        partial_load("X_val_1.npy", val_ratio)
    ])
    y_val = np.concatenate([
        partial_load("y_val_0.npy", val_ratio),
        partial_load("y_val_1.npy", val_ratio)
    ])
    return X_train, y_train, X_val, y_val

# âœ… í•™ìŠµ ë° í‰ê°€
def run_minirocket_rf(X_train, y_train, X_val, y_val):
    X_train = np.transpose(X_train, (0, 2, 1))
    X_val = np.transpose(X_val, (0, 2, 1))

    pipeline = make_pipeline(
        MiniRocketWrapper(num_kernels=1000),
        StandardScaler(),
        RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=42)
    )

    pipeline.fit(X_train, y_train)

    # âœ… ì €ì¥
    joblib.dump(pipeline, model_save_path)
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")

    # âœ… í•™ìŠµ í‰ê°€
    y_train_pred = pipeline.predict(X_train)
    y_train_score = pipeline.predict_proba(X_train)[:, 1]

    print("\nâœ… [Train Set] í‰ê°€ ê²°ê³¼")
    print(classification_report(y_train, y_train_pred, digits=4))
    print(f"AUC       : {roc_auc_score(y_train, y_train_score):.4f}")
    print(f"F1-score  : {f1_score(y_train, y_train_pred):.4f}")
    print(f"Precision : {precision_score(y_train, y_train_pred):.4f}")
    print(f"Recall    : {recall_score(y_train, y_train_pred):.4f}")

    # âœ… ê²€ì¦ í‰ê°€
    y_val_pred = pipeline.predict(X_val)
    y_val_score = pipeline.predict_proba(X_val)[:, 1]

    print("\nğŸ“Š [Validation Set] í‰ê°€ ê²°ê³¼")
    print(classification_report(y_val, y_val_pred, digits=4))
    print(f"AUC       : {roc_auc_score(y_val, y_val_score):.4f}")
    print(f"F1-score  : {f1_score(y_val, y_val_pred):.4f}")
    print(f"Precision : {precision_score(y_val, y_val_pred):.4f}")
    print(f"Recall    : {recall_score(y_val, y_val_pred):.4f}")

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    X_train, y_train, X_val, y_val = load_data(split_dir, train_ratio=0.6, val_ratio=0.6)
    print(f"âœ… í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(X_train)}, ê²€ì¦ ìƒ˜í”Œ ìˆ˜: {len(X_val)}")
    print("ğŸš€ MiniRocket + RandomForest í•™ìŠµ ì‹œì‘")
    run_minirocket_rf(X_train, y_train, X_val, y_val)
