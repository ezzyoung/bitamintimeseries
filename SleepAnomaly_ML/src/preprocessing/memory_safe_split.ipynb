{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0dfcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: 0 â†’ train: (68712, 10, 6000), val: (17178, 10, 6000)\n",
      "âœ… ì €ì¥ ì™„ë£Œ: 1 â†’ train: (69749, 10, 6000), val: (17438, 10, 6000)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“„ src/preprocessing/split_dataset.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "\n",
    "\n",
    "def stream_split_save_lazy(x_path, y_path, save_dir, label_name, test_size=0.2, chunk_size=100, random_state=42):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    X_memmap = np.load(x_path, mmap_mode='r')\n",
    "    y_array = np.load(y_path)\n",
    "    total = X_memmap.shape[0]\n",
    "\n",
    "    train_X_path = os.path.join(save_dir, f'X_train_{label_name}.npy')\n",
    "    val_X_path = os.path.join(save_dir, f'X_val_{label_name}.npy')\n",
    "    train_y_path = os.path.join(save_dir, f'y_train_{label_name}.npy')\n",
    "    val_y_path = os.path.join(save_dir, f'y_val_{label_name}.npy')\n",
    "\n",
    "    # ë¹ˆ ë°°ì—´ ìƒì„± (ì‚¬ì´ì¦ˆ ëª¨ë¥´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ì„ì‹œ ì €ì¥)\n",
    "    X_train_list, y_train_list, X_val_list, y_val_list = [], [], [], []\n",
    "\n",
    "    for i in range(0, total, chunk_size):\n",
    "        end = min(i + chunk_size, total)\n",
    "        try:\n",
    "            X_chunk = np.array(X_memmap[i:end], dtype=np.float32)\n",
    "        except MemoryError:\n",
    "            print(f\"âŒ MemoryError at chunk {i}:{end}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        y_chunk = y_array[i:end]\n",
    "\n",
    "        X_tr, X_v, y_tr, y_v = train_test_split(\n",
    "            X_chunk, y_chunk, test_size=test_size, random_state=random_state, stratify=y_chunk\n",
    "        )\n",
    "\n",
    "        X_train_list.append(X_tr)\n",
    "        y_train_list.append(y_tr)\n",
    "        X_val_list.append(X_v)\n",
    "        y_val_list.append(y_v)\n",
    "\n",
    "    # ì €ì¥ (ìµœì¢… ë³‘í•©)\n",
    "    np.save(train_X_path, np.concatenate(X_train_list, axis=0))\n",
    "    np.save(train_y_path, np.concatenate(y_train_list, axis=0))\n",
    "    np.save(val_X_path, np.concatenate(X_val_list, axis=0))\n",
    "    np.save(val_y_path, np.concatenate(y_val_list, axis=0))\n",
    "\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {label_name} â†’ train: {np.concatenate(X_train_list).shape}, val: {np.concatenate(X_val_list).shape}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stream_split_save_lazy(\n",
    "        x_path=\"../../Database/processed/X_label0.npy\",\n",
    "        y_path=\"../../Database/processed/y_label0.npy\",\n",
    "        save_dir=\"../../Database/processed/split\",\n",
    "        label_name=\"0\"\n",
    "    )\n",
    "    stream_split_save_lazy(\n",
    "        x_path=\"../../Database/processed/X_label1.npy\",\n",
    "        y_path=\"../../Database/processed/y_label1.npy\",\n",
    "        save_dir=\"../../Database/processed/split\",\n",
    "        label_name=\"1\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada25a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
